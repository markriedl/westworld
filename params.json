{
  "name": "Westworld",
  "tagline": "",
  "body": "# Westworld Background\r\nThis repository was developed to accompany MEDIUM_POST.\r\n\r\nI assume you are familiar with the HBO TV series [Westworld](https://en.wikipedia.org/wiki/Westworld_(TV_series)). At the time this repository was created, I have only watched the first episode. \r\n\r\nFor the purposes of this document, you only need to know that Westworld involves an amusement park populated by lifelike robots. Some humans abuse the robots. At the end of the day, robot memories are erased. However, there are hints that their memories are not perfectly erased and that they are remembering past abuses.\r\n\r\nLet's pretend that the robots in Westworld use **reinforcement learning**, in which AI and robots learn from trial and error. We don't know what technology the robots in Westworld actually use (there are hints about massive scripting efforts). However, at this time reinforcement learning is one of the preferred techniques by AI researchers for creating autonomous systems. \r\n\r\nWe will look at what happens when humans torture reinforcement learning robots as they are learning. We will look at why, despite the torture, robots are unlikely to harm humans in return. We will also look at the effects of memories that are not perfectly erased.\r\n\r\n# Background: Reinforcement Learning\r\n\r\nTBW\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}